---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# Coming Soon

<!-- # About me
I am currently a fourth-year undergraduate student at Peking University, School of Electronics Engineering and Computer Science. 
My research interest mainly lies in Robotics, Computer Vision and Machine Learning. It’s mainly about robot manipulation: to learn versatile skills and generalization ability through novel representations or novel algorithms. Targeted application might include domestic robots or other autonomous manipulation tasks. Supervised by [Prof. Hao Dong](https://zsdonghao.github.io/), I worked as an undergraduate member in [Center on Frontiers of Computing Studies (CFCS)](https://cfcs.pku.edu.cn/english/), and I have been lucky to work with [Prof. Hao Dong](https://zsdonghao.github.io/), [Prof. Leonidas J. Guibas](https://geometry.stanford.edu/member/guibas/), [Dr. Kaichun Mo](https://www.cs.stanford.edu/~kaichun), [Dr. Jie Fu](https://bigaidream.github.io/) and [Dr. Qingnan Fan](https://fqnchina.github.io/).


# 🔥 News
- *Autumn 2022*: &nbsp;Looking for a PhD position in 2023 fall.
- *Autumn 2022*: &nbsp;🎉🎉 Our paper AdaAfford gets accepted to ECCV 2022.

# 📝 Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2022</div><img src='https://wangyian-me.github.io/images/adagif2.gif' alt="sym" width="500" height="300"></div></div>
<div class='paper-box-text' markdown="1">

[AdaAfford: Learning to Adapt Manipulation Affordance for 3D Articulated Objects via Few-shot Interactions](https://arxiv.org/abs/2112.00246)

**Yian Wang***, [Ruihai Wu\*](https://warshallrho.github.io), [Kaichun Mo\*](https://www.cs.stanford.edu/~kaichun), Jiaqi Ke, [Qingnan Fan](https://fqnchina.github.io/), [Leonidas J. Guibas](https://geometry.stanford.edu/member/guibas/), [Hao Dong](http://zsdonghao.github.io/)

[**Paper**](https://arxiv.org/pdf/2112.00246.pdf) [**Project**](https://hyperplane-lab.github.io/AdaAfford/) [**Code**](https://github.com/wangyian-me/AdaAffordCode)
- We propose a novel framework that learns to perform very few test-time interactions for quickly adapting the affordance priors to more accurate instance-specific posteriors by eliminating the dynamic and kinematic uncertainties.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2022</div><img src='https://wangyian-me.github.io/images/vat_mart.gif' alt="sym" width="500" height="300"></div></div>
<div class='paper-box-text' markdown="1">

[VAT-Mart: Learning Visual Action Trajectory Proposals for Manipulating 3D ARTiculated Objects](https://arxiv.org/abs/2106.14440)

[Ruihai Wu\*](https://warshallrho.github.io), [Yan Zhao\*](https://www.researchgate.net/profile/Yan-Zhao-182), [Kaichun Mo\*](https://www.cs.stanford.edu/~kaichun),
[Zizheng Guo](https://guozz.cn), **Yian Wang**, [Tianhao Wu](https://moistchi.github.io/tianhaowu.github.io/), [Qingnan Fan](https://fqnchina.github.io/), [Xuelin Chen](https://xuelin-chen.github.io/), [Leonidas J. Guibas](https://geometry.stanford.edu/member/guibas/), [Hao Dong](http://zsdonghao.github.io/)

[Paper](https://arxiv.org/pdf/2106.14440.pdf) [**Project**](https://hyperplane-lab.github.io/vat-mart/) [**Code**](https://github.com/warshallrho/VAT-Mart)
- We propose an interaction-for-perception framework to predict dense geometry-aware, interaction-aware, and task-aware visual action affordance for 3D articulated objects.
</div>
</div>

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div> -->

# 🎖 Honors and Awards
- Benz Scholarship in Peking University 2020-2021		
- Lee Wai Wing Scholarship in Peking University 2019-2020
- Merit Student in Peking University 2019-2020 and 2020-2021
- Second class prize in PKU-CPC 2021
- Silver medal in National Olympiad in Informatics (NOI), China Computer Federation, 2018

# 📖 Educations
- *Autumn 2019 - Autumn 2022 (now)*, undergraduate in Peking University. 

<!-- # 💬 Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

# 💻 Internships
- *Spring 2022 - Autumn 2022 (now)*, with [Dr. Jie Fu](https://bigaidream.github.io/) in [Mila](https://mila.quebec/en/) & [BAAI](https://www.baai.ac.cn/english.html).

# other projects
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI 2020 Mahjong AI Competition</div><img src='https://wangyian-me.github.io/images/mahjong.jpg' alt="sym" width="500" height="300"></div></div>
<div class='paper-box-text' markdown="1">

[King of gambler](https://github.com/kylelv2000/mahjong)

**Yian Wang**, [Kunhang Lv](https://github.com/kylelv2000), [Zhehuan Chen](https://acmlczh.github.io/)

[**Paper**](https://www.botzone.org.cn/static/IJCAI2020MahjongPPT/15-King%20of%20gambler-komqaq-paper.pdf) [**Project**](https://kylelv.com/?p=726) [**Code**](https://github.com/kylelv2000/mahjong)
- We apply Depth First Search and pruning algorithm to compute our possibility of winning and analyze our complexity by combinatorial mathematics.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Course project</div><img src='https://wangyian-me.github.io/images/pkbg.gif' alt="sym" width="500" height="300"></div></div>
<div class='paper-box-text' markdown="1">

[PKBG](https://github.com/wangyian-me/PKBG)

**Yian Wang**, [Zhehuan Chen](https://acmlczh.github.io/)

[**Project**](https://github.com/wangyian-me/PKBG) [**Code**](https://github.com/wangyian-me/PKBG)
- We self-design the task setting and run reinforcement learning ([TD3](https://github.com/sfujim/TD3)) on two competing agents to see what interesting strategy they will develop.
</div>
</div> -->

